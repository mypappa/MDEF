For this microchallenge I decided to work on the MDEFest project I'm doing with Stella and not to continue with the 'andaaza' project of the two previous microchallenges. The time until the end is very short and we thought that this last intensive week with all the resources available was the perfect opportunity to build a technical base for what we envision.   
Besides, I felt that the old project was sort of done - for what it was meant to be.  

So we started working on it immediately. We had to concentrate and make decisions quickly so that we had more time to work on it later. We soon realized that our initial plan was a bit too ambitious, considering the time and our non-existent background in programming.   

the main idea for the MDEFest was to build an interactive installation where humans and artificial intelligences collaborate to co-create a story in real time. inspired by the live coding session with Citlali Hern√°ndez, we we thinking of using a software like hydra that creates visuals while the user is changing the code.  

it was important for us though that the AIs would play an important role in the making of the story (so it can be called 'more than human' and not just use them as tools to visualise the collective human's input   

then we started wondering..  
What happens if we revert the roles between the users and the servers?  
How can I become the assistant of an AI? then who is the master of whom?  

therefore, in the end we created an interface that records speech, transcribes it to text and feeds it into a language model (which in this case is GPT). Then the AI starts generating a story. The story always ends with a question to the participants for new human input. The answer is then integrated to the story from the AI, live-projected and ends with another question. this continues until we reach an x amount of words.  

visit our [repo](https://github.com/mypappa/morethanai/blob/main/README.md) to read more about the project 